{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBAGOP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I1KWBzo24Huy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFPh9-UNMfiq",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbcfcnz2nz-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11ad33f6-eefe-47cd-bb78-a2d0848a50fb"
      },
      "source": [
        "#IMPORT NECESSARY LIBRARIES AND ESTABLISH LINK WITH FILES\n",
        "import keras\n",
        "keras.__version__\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import re\n",
        "\n",
        "np.set_printoptions(threshold=np.inf) #Prevents array truncation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIgS4WaTMlX6",
        "colab_type": "text"
      },
      "source": [
        "# Making the data usable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76FLU9Dpn-Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "header=['NAME','TEAM','AGE','GP','W','L','MIN','OFFRTG','DEFRTG','NETRTG','AST%','AST/TO','AST Ratio','OREB%','DREB%','REB%','TO Ratio','eFG%','TS%','USG%','PACE','PI']\n",
        "col = {}\n",
        "for i in np.arange(len(header)):\n",
        "  col[header[i]]=i\n",
        "\n",
        "target_header=['TEAM','SEASON','AGAINST TEAM','WIN/LOSS']\n",
        "target_column = {}\n",
        "for i in np.arange(len(target_header)):\n",
        "  target_column[target_header[i]]=i\n",
        "  \n",
        "    \n",
        "os.chdir(\"/content/drive/My Drive/sports\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxBHUevEZNFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "winfile = ['sports 96-97.txt', 'sports 97-98.txt', 'sports 98-99.txt', 'sports 99-00.txt', 'sports 00-01.txt', \n",
        "           'sports 01-02.txt', 'sports 02-03.txt', 'sports 03-04.txt', 'sports 04-05.txt', 'sports 05-06.txt',\n",
        "           'sports 06-07.txt', 'sports 07-08.txt', 'sports 08-09.txt', 'sports 09-10.txt', 'sports 10-11.txt',\n",
        "           'sports 11-12.txt', 'sports 12-13.txt', 'sports 13-14.txt', 'sports 14-15.txt', 'sports 15-16.txt',\n",
        "           'sports 16-17.txt', 'sports 17-18.txt', 'sports 18-19.txt', 'sports 19-20.txt']\n",
        "\n",
        "final_tensor = np.zeros((24,541,22))\n",
        "\n",
        "fspecial = re.sub('\\n','\\t',open('Target Data Points by team.txt').read()).split('\\t')[4:]\n",
        "\n",
        "for q in range(len(winfile)):\n",
        "  \n",
        "  infile = winfile[q]\n",
        "  text = open(infile).read()\n",
        "  oneline = re.sub('\\n', '\\t', text)\n",
        "  f = oneline.split('\\t')\n",
        "\n",
        "\n",
        "  pnum = {}\n",
        "  tnum = {}\n",
        "  team = {}\n",
        "  name = []\n",
        "\n",
        "  cols = len(header)\n",
        "  rows = int(len(f)/(len(header)))\n",
        "\n",
        "  stats = np.zeros((rows+5,cols))\n",
        "\n",
        "  teami=1\n",
        "  for i in np.arange(rows):\n",
        "    n = i*(cols)\n",
        "    newname = f[n]\n",
        "    if f[n+1] not in tnum:\n",
        "      tnum[f[n+1]] = teami\n",
        "      teami += 1\n",
        "    f[n+1] = tnum[f[n+1]]\n",
        "    if newname not in pnum:\n",
        "      name.append(newname)\n",
        "      pnum[name[i]] = i\n",
        "      f[n] = pnum[f[n]]\n",
        "      team[name[i]] = f[n+1]\n",
        "      for j in np.arange(cols):\n",
        "        stats[i,j] = f[n+j]\n",
        "  for i in range(len(fspecial)//4):\n",
        "    n = i*4\n",
        "    if int(fspecial[n+1]) == q+1:\n",
        "      fspecial[n] = tnum[fspecial[n]]\n",
        "      fspecial[n+2] = tnum[fspecial[n+2]]\n",
        "  for i in range(cols):\n",
        "    for j in range(rows):\n",
        "      final_tensor[q,j,i]=stats[j,i]\n",
        "\n",
        "target_tensor=np.zeros(len(fspecial))\n",
        "for i in range(len(fspecial)):\n",
        "  target_tensor[i] = fspecial[i]\n",
        "target_tensor = target_tensor.reshape((len(fspecial)//4,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZX-01k070-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_tensor[:,:,1])\n",
        "#ngame = 0\n",
        "#nsea = target_column[ngame,1]\n",
        "#team = target_column[game,0]\n",
        "#home = final_tensor[nsea,final_tensor[nsea,:,1]==team,2:22]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUxaSTsuMb0j",
        "colab_type": "text"
      },
      "source": [
        "# Rescaling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOTfkjE0KgUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######Rescaling data\n",
        "#################################################################################\n",
        "##########First 11 seasons are training data, next 5 are validation, next 8 are test data\n",
        "#WE MUST MEAN-SUBTRACT AND STD-DIVIDE BY THE MEAN AND STD OF THE ENTIRE TRAINING SET\n",
        "for n in range(2,22):\n",
        "  final_tensor_slice = final_tensor[:,:,n]\n",
        "  final_tensor_slice = final_tensor_slice.reshape(541*24)\n",
        "  new_list = []\n",
        "  for i in range(541*11):\n",
        "    if final_tensor_slice[i] != int(0):\n",
        "      new_list.append(final_tensor_slice[i])\n",
        "  avg = np.mean(new_list)\n",
        "  std = np.std(new_list)\n",
        "\n",
        "  for i in range(len(final_tensor_slice)):\n",
        "    if abs(final_tensor_slice[i]) != int(0):\n",
        "      final_tensor_slice[i] = (final_tensor_slice[i]-avg)/std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBpTxbk_QuyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infile = 'Target Data Points by team.txt'\n",
        "text = open(infile).read()\n",
        "#oneline = re.sub('\\t', '', text)\n",
        "f = text.split('\\n')\n",
        "f = f[1:]\n",
        "\n",
        "hteam = []\n",
        "ateam = []\n",
        "nsea = []\n",
        "labels = []\n",
        "for i in np.arange(len(f)):\n",
        "  z = f[i].split('\\t')\n",
        "  hteam.append(z[0])\n",
        "  ateam.append(z[2])\n",
        "  nsea.append(int(z[1]))\n",
        "  labels.append(z[3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FYc5D3QB55Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxplayers = 25\n",
        "home = []\n",
        "away =[]\n",
        "inmat = np.zeros((len(labels),maxplayers,20,2))\n",
        "for ig in np.arange(len(labels)):\n",
        "  if hteam[ig] in tnum and ateam[ig] in tnum:\n",
        "    hnum = tnum[hteam[ig]]\n",
        "    anum = tnum[ateam[ig]]\n",
        "    home = final_tensor[nsea[ig]-1,final_tensor[nsea[ig]-1,:,1]==hnum,2:22]\n",
        "    away = final_tensor[nsea[ig]-1,final_tensor[nsea[ig]-1,:,1]==anum,2:22]\n",
        "    nhplay = np.shape(home)[0]\n",
        "    naplay = np.shape(away)[0]\n",
        "    inmat[ig,0:nhplay,:,0] = home\n",
        "    inmat[ig,0:naplay,:,1] = away"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlK2CpTqW08g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = keras.utils.to_categorical(labels)\n",
        "print(np.shape(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2QN5GnMH7ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make the training and testing sets\n",
        "train_data = inmat[:13875,:,:,:]\n",
        "train_targets = labels[:13875,:]\n",
        "val_data = inmat[13875:20660,:,:,:]\n",
        "val_targets = labels[13875:20660,:]\n",
        "test_data = inmat[20660:,:,:]\n",
        "test_targets = labels[20660:,:]\n",
        "#NEED TO FIGURE OUT WHAT FROM THE TARGET TENSOR IS NECESSARY\n",
        "#premature\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptRHoqR6X90M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I_Vebqxgd7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_tensor[:,:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1KWBzo24Huy",
        "colab_type": "text"
      },
      "source": [
        "# In case you want to test that it worked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anb631Mdp6Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##96-97\n",
        "query = 0\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M82-WhZmqoqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##97-98\n",
        "query = 1\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUNzlz2Ntu2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##98-99\n",
        "query = 2\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG-rWtq4t1HP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##99-00\n",
        "query = 3\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y85xWXht3JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##00-01\n",
        "query = 4\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghj7MEct34z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##01-02\n",
        "query = 5\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ0Ex60Jt4ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#02-03\n",
        "query = 6\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpzvWjPet4zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#03-04\n",
        "query = 7\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJnpG0gst4_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#04-05\n",
        "query = 8\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FamS46gQt44l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#05-06\n",
        "query = 9\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71WNKoYht4tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#06-07\n",
        "query = 10\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWIbWYTtt4Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#07-08\n",
        "query = 11\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc_qjAt-uDe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#08-09\n",
        "query = 12\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOwuJ0ypuFx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#09-10\n",
        "query = 13\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KhuGKH6uG_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10-11\n",
        "query = 14\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipu5l-zauHK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#11-12\n",
        "query = 15\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn3vg842uHY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#12-13\n",
        "query = 16\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfSVh5TAuHqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#13-14\n",
        "query = 17\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvXeLU0AuH59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#14-15\n",
        "query = 18\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLYZ1MsGuIHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#15-16\n",
        "query = 19\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvsUlOqSuHvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#16-17\n",
        "query = 20\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwBZkld3uHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#17-18\n",
        "query = 21\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPwYerppuHPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#18-19\n",
        "query = 22\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmuxGbvYuHEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##18-19\n",
        "query = 23\n",
        "print(final_tensor[query,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hx4DP4CuG3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRsLM953BJF0",
        "colab_type": "text"
      },
      "source": [
        "# This is the part where we get the model together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTMpBRivH3O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu',\n",
        "                       input_shape=(maxplayers,20,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "num_epochs = 50  # For each partition, run 200 epochs to train.\n",
        "all_mae_histories = [] # Save each history, so we can see how it does\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    train_targets,\n",
        "                    epochs=20,\n",
        "                    validation_data=(val_data, val_targets))\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufo5rlKFYmXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'bx-', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'bx-', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v56jE-9cbSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the code here that trains the model, but instead of going all the way out to 20 epochs, stop at the epoch you think makes the most sense.\n",
        "best_epoch = 5 # Change this!!!\n",
        "model.fit(train_data, train_targets, epochs=best_epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IDrHHUdcmP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(test_data, test_targets)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIAgpdDocpW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "print(np.shape(predictions))\n",
        "print('Review\\tLabel\\tPrediction')\n",
        "for i in np.arange(30):\n",
        "  print(i, '\\t',test_labels[i],'\\t',predictions[i]) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpgoUan8dEcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FROM THE BOSTON HOUSING MODEL EXAMPLE\n",
        "\n",
        "def build_model():\n",
        "    # Because we will need to instantiate\n",
        "    # the same model multiple times,\n",
        "    # we use a function to construct it.\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 200  # For each partition, run 200 epochs to train.\n",
        "all_mae_histories = [] # Save each history, so we can see how it does\n",
        "\n",
        "k = 4 # Use four partitions\n",
        "num_val_samples = len(train_data) // k # Divide by k and round down\n",
        "\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(average_mae_history)\n",
        "#plt.plot(average_mae_history[10:])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get a fresh, compiled model.\n",
        "max_epoch = 48\n",
        "model = build_model()\n",
        "# Train it on the entirety of the data.\n",
        "model.fit(train_data, train_targets,\n",
        "          epochs=max_epoch, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_mae_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "plt.plot(predictions[:,0],'r.',label='Predictions')\n",
        "plt.plot(test_targets,'bx',label='Targets')\n",
        "plt.ylabel('Cost of House (k$)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "resid = predictions[:,0]-test_targets\n",
        "plt.plot(resid,'g+')\n",
        "plt.ylabel('Diff. btw. Prediction and Actual')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(resid,bins=20)\n",
        "plt.xlabel('Diff. btw. Prediction and Actual')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_mae = []  # Set up an empty array to keep the results\n",
        "\n",
        "for i in np.arange(13): # Loop through the 13 inputs\n",
        "  permutation = np.copy(test_data) # Make a copy of the test data\n",
        "  permutation[:,i] = 0.0 # Set a particular column of inputs to zero\n",
        "  p_mse, p_mae = model.evaluate(permutation, test_targets) # evaluate the modified data\n",
        "  new_mae.append(p_mae-test_mae_score) # save the change in MAE to the array\n",
        "\n",
        "plt.bar(np.arange(13)+1,new_mae) # Make a bar graph to show change in result\n",
        "plt.ylabel('Change in MAE')\n",
        "plt.xlabel('Parameter Number (see list above)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 200  # For each partition, run 200 epochs to train.\n",
        "all_mae_histories = [] # Save each history, so we can see how it does\n",
        "\n",
        "k = 5 # Use four partitions\n",
        "num_val_samples = len(train_data) // k # Divide by k and round down\n",
        "\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(average_mae_history)\n",
        "#plt.plot(average_mae_history[10:])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
